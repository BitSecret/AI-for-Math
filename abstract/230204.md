# 13 papers from arxiv about "AI for Math" from 1 Jan to 5 Feb

### Towards Autoformalization of Mathematics and Code Correctness: Experiments with Elementary Proofs
**source**: arXiv:2301.02195 [[paper](https://arxiv.org/abs/2301.02195)]
**abstract**: The ever-growing complexity of mathematical proofs makes their manualverification by mathematicians very cognitively demanding. Autoformalizationseeks to address this by translating proofs written in natural language into aformal representation that is computer-verifiable via interactive theoremprovers. In this paper, we introduce a semantic parsing approach, based on theUniversal Transformer architecture, that translates elementary mathematicalproofs into an equivalent formalization in the language of the Coq interactivetheorem prover. The same architecture is also trained to translate simpleimperative code decorated with Hoare triples into formally verifiable proofs ofcorrectness in Coq. Experiments on a limited domain of artificial andhuman-written proofs show that the models generalize well to intermediatelengths not seen during training and variations in natural language.

### Pattern Recognition Experiments on Mathematical Expressions
**source**: arXiv:2301.01624 [[paper](https://arxiv.org/abs/2301.01624)]
**abstract**: We provide the results of pattern recognition experiments on mathematicalexpressions.  We give a few examples of conjectured results. None of which was thoroughlychecked for novelty. We did not attempt to prove all the relations found andfocused on their generation.

### Learning to solve arithmetic problems with a virtual abacus
**source**: arXiv:2301.06870 [[paper](https://arxiv.org/abs/2301.06870)]
**abstract**: Acquiring mathematical skills is considered a key challenge for modernArtificial Intelligence systems. Inspired by the way humans discover numericalknowledge, here we introduce a deep reinforcement learning framework thatallows to simulate how cognitive agents could gradually learn to solvearithmetic problems by interacting with a virtual abacus. The proposed modelsuccessfully learn to perform multi-digit additions and subtractions, achievingan error rate below 1% even when operands are much longer than those observedduring training. We also compare the performance of learning agents receiving adifferent amount of explicit supervision, and we analyze the most common errorpatterns to better understand the limitations and biases resulting from ourdesign choices.

### Tracing and Manipulating Intermediate Values in Neural Math Problem Solvers
**source**: arXiv:2301.06758 [[paper](https://arxiv.org/abs/2301.06758)]
**abstract**: How language models process complex input that requires multiple steps ofinference is not well understood. Previous research has shown that informationabout intermediate values of these inputs can be extracted from the activationsof the models, but it is unclear where that information is encoded and whetherthat information is indeed used during inference. We introduce a method foranalyzing how a Transformer model processes these inputs by focusing on simplearithmetic problems and their intermediate values. To trace where informationabout intermediate values is encoded, we measure the correlation betweenintermediate values and the activations of the model using principal componentanalysis (PCA). Then, we perform a causal intervention by manipulating modelweights. This intervention shows that the weights identified via tracing arenot merely correlated with intermediate values, but causally related to modelpredictions. Our findings show that the model has a locality to certainintermediate values, and this is useful for enhancing the interpretability ofthe models.

### Symbolic expression generation via Variational Auto-Encoder
**source**: arXiv:2301.06064 [[paper](https://arxiv.org/abs/2301.06064)]
**abstract**: There are many problems in physics, biology, and other natural sciences inwhich symbolic regression can provide valuable insights and discover new lawsof nature. A widespread Deep Neural Networks do not provide interpretablesolutions. Meanwhile, symbolic expressions give us a clear relation betweenobservations and the target variable. However, at the moment, there is nodominant solution for the symbolic regression task, and we aim to reduce thisgap with our algorithm. In this work, we propose a novel deep learningframework for symbolic expression generation via variational autoencoder (VAE).In a nutshell, we suggest using a VAE to generate mathematical expressions, andour training strategy forces generated formulas to fit a given dataset. Ourframework allows encoding apriori knowledge of the formulas into fast-checkpredicates that speed up the optimization process. We compare our method tomodern symbolic regression benchmarks and show that our method outperforms thecompetitors under noisy conditions. The recovery rate of SEGVAE is 65% on theNgyuen dataset with a noise level of 10%, which is better than the previouslyreported SOTA by 20%. We demonstrate that this value depends on the dataset andcan be even higher.

### Towards a Holistic Understanding of Mathematical Questions with Contrastive Pre-training
**source**: arXiv:2301.07558 [[paper](https://arxiv.org/abs/2301.07558)]
**abstract**: Understanding mathematical questions effectively is a crucial task, which canbenefit many applications, such as difficulty estimation. Researchers havedrawn much attention to designing pre-training models for questionrepresentations due to the scarcity of human annotations (e.g., labelingdifficulty). However, unlike general free-format texts (e.g., user comments),mathematical questions are generally designed with explicit purposes andmathematical logic, and usually consist of more complex content, such asformulas, and related mathematical knowledge (e.g., Function). Therefore, theproblem of holistically representing mathematical questions remainsunderexplored. To this end, in this paper, we propose a novel contrastivepre-training approach for mathematical question representations, namely QuesCo,which attempts to bring questions with more similar purposes closer.Specifically, we first design two-level question augmentations, includingcontent-level and structure-level, which generate literally diverse questionpairs with similar purposes. Then, to fully exploit hierarchical information ofknowledge concepts, we propose a knowledge hierarchy-aware rank strategy(KHAR), which ranks the similarities between questions in a fine-grainedmanner. Next, we adopt a ranking contrastive learning task to optimize ourmodel based on the augmented and ranked questions. We conduct extensiveexperiments on two real-world mathematical datasets. The experimental resultsdemonstrate the effectiveness of our model.

### Discover governing differential equations from evolving systems
**source**: arXiv:2301.07863 [[paper](https://arxiv.org/abs/2301.07863)]
**abstract**: Discovering the governing equations of evolving systems from availableobservations is essential and challenging. However, current methods does notcapture the situation that underlying system dynamics can be changed.Evolvingsystems are changing over time, which invariably changes with system status.Thus, finding the exact change points is critical. We propose an onlinemodeling method capable of handling samples one by one sequentially by modelingstreaming data instead of processing the entire dataset. The proposed methodperforms well in discovering ordinary differential equations, partialdifferential equations (PDEs), and high-dimensional PDEs from streaming data.The measurement generated from a changed system is distributed dissimilarly tobefore; hence, the difference can be identified by the proposed method. Ourproposal performs well in identifying the change points and discoveringgoverning differential equations in two evolving systems.

### Can an AI Win Ghana's National Science and Maths Quiz? An AI Grand Challenge for Education
**source**: arXiv:2301.13089 [[paper](https://arxiv.org/abs/2301.13089)]
**abstract**: There is a lack of enough qualified teachers across Africa which hampersefforts to provide adequate learning support such as educational questionanswering (EQA) to students. An AI system that can enable students to askquestions via text or voice and get instant answers will make high-qualityeducation accessible. Despite advances in the field of AI, there exists norobust benchmark or challenge to enable building such an (EQA) AI within theAfrican context. Ghana's National Science and Maths Quiz competition (NSMQ) isthe perfect competition to evaluate the potential of such an AI due to its widecoverage of scientific fields, variety of question types, highly competitivenature, and live, real-world format. The NSMQ is a Jeopardy-style annual livequiz competition in which 3 teams of 2 students compete by answering questionsacross biology, chemistry, physics, and math in 5 rounds over 5 progressivestages until a winning team is crowned for that year. In this position paper,we propose the NSMQ AI Grand Challenge, an AI Grand Challenge for Educationusing Ghana's National Science and Maths Quiz competition (NSMQ) as a casestudy. Our proposed grand challenge is to "Build an AI to compete live inGhana's National Science and Maths Quiz (NSMQ) competition and win - performingbetter than the best contestants in all rounds and stages of the competition."We describe the competition, and key technical challenges to address along withideas from recent advances in machine learning that could be leveraged to solvethis challenge. This position paper is a first step towards conquering such achallenge and importantly, making advances in AI for education in the Africancontext towards democratizing high-quality education across Africa.

### Mathematics, word problems, common sense, and artificial intelligence
**source**: arXiv:2301.09723 [[paper](https://arxiv.org/abs/2301.09723)]
**abstract**: The paper discusses the capacities and limitations of current artificialintelligence (AI) technology to solve word problems that combine elementaryknowledge with commonsense reasoning. No existing AI systems can solve thesereliably. We review three approaches that have been developed, using AI naturallanguage technology: outputting the answer directly, outputting a computerprogram that solves the problem, and outputting a formalized representationthat can be input to an automated theorem verifier. We review some benchmarksthat have been developed to evaluate these systems and some experimentalstudies. We discuss the limitations of the existing technology at solving thesekinds of problems. We argue that it is not clear whether these kinds oflimitations will be important in developing AI technology for pure mathematicalresearch, but that they will be important in applications of mathematics, andmay well be important in developing programs capable of reading andunderstanding mathematical content written by humans.

### Fast Resolution Agnostic Neural Techniques to Solve Partial Differential Equations
**source**: arXiv:2301.13331 [[paper](https://arxiv.org/abs/2301.13331)]
**abstract**: Numerical approximations of partial differential equations (PDEs) areroutinely employed to formulate the solution of physics, engineering andmathematical problems involving functions of several variables, such as thepropagation of heat or sound, fluid flow, elasticity, electrostatics,electrodynamics, and more. While this has led to solving many complexphenomena, there are still significant limitations. Conventional approachessuch as Finite Element Methods (FEMs) and Finite Differential Methods (FDMs)require considerable time and are computationally expensive. In contrast,machine learning-based methods such as neural networks are faster once trained,but tend to be restricted to a specific discretization. This article aims toprovide a comprehensive summary of conventional methods and recent machinelearning-based methods to approximate PDEs numerically. Furthermore, wehighlight several key architectures centered around the neural operator, anovel and fast approach (1000x) to learning the solution operator of a PDE. Wewill note how these new computational approaches can bring immense advantagesin tackling many problems in fundamental and applied physics.

### Mathematical Capabilities of ChatGPT
**source**: arXiv:2301.13867 [[paper](https://arxiv.org/abs/2301.13867)]
**abstract**: We investigate the mathematical capabilities of ChatGPT by testing it onpublicly available datasets, as well as hand-crafted ones, and measuring itsperformance against other models trained on a mathematical corpus, such asMinerva. We also test whether ChatGPT can be a useful assistant to professionalmathematicians by emulating various use cases that come up in the dailyprofessional activities of mathematicians (question answering, theoremsearching). In contrast to formal mathematics, where large databases of formalproofs are available (e.g., the Lean Mathematical Library), current datasets ofnatural-language mathematics, used to benchmark language models, only coverelementary mathematics. We address this issue by introducing a new dataset:GHOSTS. It is the first natural-language dataset made and curated by workingresearchers in mathematics that (1) aims to cover graduate-level mathematicsand (2) provides a holistic overview of the mathematical capabilities oflanguage models. We benchmark ChatGPT on GHOSTS and evaluate performanceagainst fine-grained criteria. We make this new dataset publicly available toassist a community-driven comparison of ChatGPT with (future) large languagemodels in terms of advanced mathematical comprehension. We conclude thatcontrary to many positive reports in the media (a potential case of selectionbias), ChatGPT's mathematical abilities are significantly below those of anaverage mathematics graduate student. Our results show that ChatGPT oftenunderstands the question but fails to provide correct solutions. Hence, if yourgoal is to use it to pass a university exam, you would be better off copyingfrom your average peer!

### Reinforcement learning-based estimation for partial differential equations
**source**: arXiv:2302.01189 [[paper](https://arxiv.org/abs/2302.01189)]
**abstract**: In systems governed by nonlinear partial differential equations such as fluidflows, the design of state estimators such as Kalman filters relies on areduced-order model (ROM) that projects the original high-dimensional dynamicsonto a computationally tractable low-dimensional space. However, ROMs are proneto large errors, which negatively affects the performance of the estimator.Here, we introduce the reinforcement learning reduced-order estimator (RL-ROE),a ROM-based estimator in which the correction term that takes in themeasurements is given by a nonlinear policy trained through reinforcementlearning. The nonlinearity of the policy enables the RL-ROE to compensateefficiently for errors of the ROM, while still taking advantage of theimperfect knowledge of the dynamics. Using examples involving the Burgers andNavier-Stokes equations, we show that in the limit of very few sensors, thetrained RL-ROE outperforms a Kalman filter designed using the same ROM.Moreover, it yields accurate high-dimensional state estimates for referencetrajectories corresponding to various physical parameter values, without directknowledge of the latter.

### An Enhanced V-cycle MgNet Model for Operator Learning in Numerical Partial Differential Equations
**source**: arXiv:2302.00938 [[paper](https://arxiv.org/abs/2302.00938)]
**abstract**: This study used a multigrid-based convolutional neural network architectureknown as MgNet in operator learning to solve numerical partial differentialequations (PDEs). Given the property of smoothing iterations in multigridmethods where low-frequency errors decay slowly, we introduced a low-frequencycorrection structure for residuals to enhance the standard V-cycle MgNet. Theenhanced MgNet model can capture the low-frequency features of solutionsconsiderably better than the standard V-cycle MgNet. The numerical resultsobtained using some standard operator learning tasks are better than thoseobtained using many state-of-the-art methods, demonstrating the efficiency ofour model.Moreover, numerically, our new model is more robust in case of low-and high-resolution data during training and testing, respectively.
