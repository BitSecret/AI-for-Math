# 9 papers from arxiv about "AI for Math" from 6 Feb to 19 Feb

### Techniques to Improve Neural Math Word Problem Solvers
**source**: arXiv:2302.03145 [[paper](https://arxiv.org/abs/2302.03145)]  
**abstract**: Developing automatic Math Word Problem (MWP) solvers is a challenging taskthat demands the ability of understanding and mathematical reasoning over thenatural language. Recent neural-based approaches mainly encode the problem textusing a language model and decode a mathematical expression over quantities andoperators iteratively. Note the problem text of a MWP consists of a contextpart and a question part, a recent work finds these neural solvers may onlyperform shallow pattern matching between the context text and the goldenexpression, where question text is not well used. Meanwhile, existing decodingprocesses fail to enforce the mathematical laws into the design, where therepresentations for mathematical equivalent expressions are different. Toaddress these two issues, we propose a new encoder-decoder architecture thatfully leverages the question text and preserves step-wise commutative law.Besides generating quantity embeddings, our encoder further encodes thequestion text and uses it to guide the decoding process. At each step, ourdecoder uses Deep Sets to compute expression representations so that theseembeddings are invariant under any permutation of quantities. Experiments onfour established benchmarks demonstrate that our framework outperformsstate-of-the-art neural MWP solvers, showing the effectiveness of ourtechniques. We also conduct a detailed analysis of the results to show thelimitations of our approach and further discuss the potential future work. Codeis available at https://github.com/sophistz/Question-Aware-Deductive-MWP.

### Analyzing the Performance of Deep Encoder-Decoder Networks as Surrogates for a Diffusion Equation
**source**: arXiv:2302.03786 [[paper](https://arxiv.org/abs/2302.03786)]  
**abstract**: Neural networks (NNs) have proven to be a viable alternative to traditionaldirect numerical algorithms, with the potential to accelerate computationaltime by several orders of magnitude. In the present paper we study the use ofencoder-decoder convolutional neural network (CNN) as surrogates forsteady-state diffusion solvers. The construction of such surrogates requiresthe selection of an appropriate task, network architecture, training setstructure and size, loss function, and training algorithm hyperparameters. Itis well known that each of these factors can have a significant impact on theperformance of the resultant model. Our approach employs an encoder-decoder CNNarchitecture, which we posit is particularly well-suited for this task due toits ability to effectively transform data, as opposed to merely compressing it.We systematically evaluate a range of loss functions, hyperparameters, andtraining set sizes. Our results indicate that increasing the size of thetraining set has a substantial effect on reducing performance fluctuations andoverall error. Additionally, we observe that the performance of the modelexhibits a logarithmic dependence on the training set size. Furthermore, weinvestigate the effect on model performance by using different subsets of datawith varying features. Our results highlight the importance of sampling theconfigurational space in an optimal manner, as this can have a significantimpact on the performance of the model and the required training time. Inconclusion, our results suggest that training a model with a pre-determinederror performance bound is not a viable approach, as it does not guarantee thatedge cases with errors larger than the bound do not exist. Furthermore, as mostsurrogate tasks involve a high dimensional landscape, an ever increasingtraining set size is, in principle, needed, however it is not a practicalsolution.

### Solving Maxwell's Equation in 2D with Neural Networks with Local Converging Inputs
**source**: arXiv:2302.02860 [[paper](https://arxiv.org/abs/2302.02860)]  
**abstract**: In this paper we apply neural networks with local converging inputs (NNLCI),originally introduced in [arXiv:2109.09316], to solve the two dimensionalMaxwell's equation around perfect electric conductors (PECs). The input to thenetworks consist of local patches of low cost numerical solutions to theequation computed on two coarse grids, and the output is a more accuratesolution at the center of the local patch. We apply the recently developedsecond order finite difference method [arXiv:2209.00740] to generate the inputand training data which captures the scattering of electromagnetic waves off ofa PEC at a given terminal time. The advantage of NNLCI is that once trained itoffers an efficient alternative to costly high-resolution conventionalnumerical methods; our numerical experiments indicate the computationalcomplexity saving by a factor of $8^3$ in terms of the number ofspatial-temporal grid points. In contrast with existing research work onapplying neural networks to directly solve PDEs, our method takes advantage ofthe local domain of dependence of the Maxwell's equation in the input solutionpatches, and is therefore simpler, yet still robust. We demonstrate that we cantrain our neural network on some PECs to predict accurate solutions todifferent PECs with quite different geometries from any of the trainingexamples.

### Numerical Methods For PDEs Over Manifolds Using Spectral Physics Informed Neural Networks
**source**: arXiv:2302.05322 [[paper](https://arxiv.org/abs/2302.05322)]  
**abstract**: We introduce an approach for solving PDEs over manifolds using physicsinformed neural networks whose architecture aligns with spectral methods. Thenetworks are trained to take in as input samples of an initial condition, atime stamp and point(s) on the manifold and then output the solution's value atthe given time and point(s). We provide proofs of our method for the heatequation on the interval and examples of unique network architectures that areadapted to nonlinear equations on the sphere and the torus. We also show thatour spectral-inspired neural network architectures outperform the standardphysics informed architectures. Our extensive experimental results includegeneralization studies where the testing dataset of initial conditions israndomly sampled from a significantly larger space than the training set.

### Learning by Applying: A General Framework for Mathematical Reasoning via Enhancing Explicit Knowledge Learning
**source**: arXiv:2302.05717 [[paper](https://arxiv.org/abs/2302.05717)]  
**abstract**: Mathematical reasoning is one of the crucial abilities of general artificialintelligence, which requires machines to master mathematical logic andknowledge from solving problems. However, existing approaches are nottransparent (thus not interpretable) in terms of what knowledge has beenlearned and applied in the reasoning process. In this paper, we propose ageneral Learning by Applying (LeAp) framework to enhance existing models(backbones) in a principled way by explicit knowledge learning. In LeAp, weperform knowledge learning in a novel problem-knowledge-expression paradigm,with a Knowledge Encoder to acquire knowledge from problem data and a KnowledgeDecoder to apply knowledge for expression reasoning. The learned mathematicalknowledge, including word-word relations and word-operator relations, forms anexplicit knowledge graph, which bridges the knowledge "learning" and "applying"organically. Moreover, for problem solving, we design a semantics-enhancedmodule and a reasoning-enhanced module that apply knowledge to improve theproblem comprehension and symbol reasoning abilities of any backbone,respectively. We theoretically prove the superiority of LeAp's autonomouslearning mechanism. Experiments on three real-world datasets show that LeApimproves all backbones' performances, learns accurate knowledge, and achieves amore interpretable reasoning process.

### Do Deep Neural Networks Capture Compositionality in Arithmetic Reasoning?
**source**: arXiv:2302.07866 [[paper](https://arxiv.org/abs/2302.07866)]  
**abstract**: Compositionality is a pivotal property of symbolic reasoning. However, howwell recent neural models capture compositionality remains underexplored in thesymbolic reasoning tasks. This study empirically addresses this question bysystematically examining recently published pre-trained seq2seq models with acarefully controlled dataset of multi-hop arithmetic symbolic reasoning. Weintroduce a skill tree on compositionality in arithmetic symbolic reasoningthat defines the hierarchical levels of complexity along with threecompositionality dimensions: systematicity, productivity, and substitutivity.Our experiments revealed that among the three types of composition, the modelsstruggled most with systematicity, performing poorly even with relativelysimple compositions. That difficulty was not resolved even after training themodels with intermediate reasoning steps.

### Tree-Based Representation and Generation of Natural and Mathematical Language
**source**: arXiv:2302.07974 [[paper](https://arxiv.org/abs/2302.07974)]  
**abstract**: Mathematical language in scientific communications and educational scenariosis important yet relatively understudied compared to natural languages. Recentworks on mathematical language focus either on representing stand-alonemathematical expressions, especially in their natural tree format, ormathematical reasoning in pre-trained natural language models. Existing workson jointly modeling and generating natural and mathematical languages simplytreat mathematical expressions as text, without accounting for the rigidstructural properties of mathematical expressions. In this paper, we propose aseries of modifications to existing language models to jointly represent andgenerate text and math: representing mathematical expressions as sequences ofnode tokens in their operator tree format, using math symbol and tree positionembeddings to preserve the semantic and structural properties of mathematicalexpressions, and using a constrained decoding method to generate mathematicallyvalid expressions. We ground our modifications in GPT-2, resulting in a modelMathGPT, and demonstrate that it outperforms baselines on mathematicalexpression generation tasks.

### A Neural PDE Solver with Temporal Stencil Modeling
**source**: arXiv:2302.08105 [[paper](https://arxiv.org/abs/2302.08105)]  
**abstract**: Numerical simulation of non-linear partial differential equations plays acrucial role in modeling physical science and engineering phenomena, such asweather, climate, and aerodynamics. Recent Machine Learning (ML) models trainedon low-resolution spatio-temporal signals have shown new promises in capturingimportant dynamics in high-resolution signals, under the condition that themodels can effectively recover the missing details. However, this study showsthat significant information is often lost in the low-resolution down-sampledfeatures. To address such issues, we propose a new approach, namely TemporalStencil Modeling (TSM), which combines the strengths of advanced time-seriessequence modeling (with the HiPPO features) and state-of-the-art neural PDEsolvers (with learnable stencil modeling). TSM aims to recover the lostinformation from the PDE trajectories and can be regarded as a temporalgeneralization of classic finite volume methods such as WENO. Our experimentalresults show that TSM achieves the new state-of-the-art simulation accuracy for2-D incompressible Navier-Stokes turbulent flows: it significantly outperformsthe previously reported best results by 19.9% in terms of the highly-correlatedduration time and reduces the inference latency into 80%. We also show a stronggeneralization ability of the proposed method to various out-of-distributionturbulent flow settings. Our code is available at "https://github.com/Edward-Sun/TSM-PDE".

### Learning-based solutions to nonlinear hyperbolic PDEs: Empirical insights on generalization errors
**source**: arXiv:2302.08144 [[paper](https://arxiv.org/abs/2302.08144)]  
**abstract**: We study learning weak solutions to nonlinear hyperbolic partial differentialequations (H-PDE), which have been difficult to learn due to discontinuities intheir solutions. We use a physics-informed variant of the Fourier NeuralOperator (π-FNO) to learn the weak solutions. We empirically quantify thegeneralization/out-of-sample error of the π-FNO solver as a function ofinput complexity, i.e., the distributions of initial and boundary conditions.Our testing results show that $π$-FNO generalizes well to unseen initial andboundary conditions. We find that the generalization error grows linearly withinput complexity. Further, adding a physics-informed regularizer improved theprediction of discontinuities in the solution. We use theLighthill-Witham-Richards (LWR) traffic flow model as a guiding example toillustrate the results.
